[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Elaine McVey Houskeeper",
    "section": "",
    "text": "I‚Äôm the CEO at EvE Bio. We are scientific data generators, creating an open dataset that maps the activity of small molecule drugs against physiological ‚Äútargets‚Äù (druggable human proteins). We refer to this as a pharmome map. Having spent decades as a data scientist trying to do great things with flawed data, I am delighted that EvE is focused on producing a high quality dataset as our primary goal. This is enabled by organizational innovation. We are a non-profit Focused Research Organization (FRO) under Convergent Research, and were built specifically to carry out our pharmome mapping mission.\nI started my career at the bench in protein folding and cell biology labs. After a graduate degree in statistics, I worked at BD‚Äôs R&D center as a data scientist across cell therapy, diabetes technology, and smart device programs. For the last decade, I‚Äôve been establishing data science teams at startups in a variety of industries. My science, data, and business leadership experience has all come together in my role as CEO at EvE Bio.\nMy high school chemistry teacher used to say ‚Äúyour brain is in your pencil‚Äù. I find writing to be more than a way to share my ideas; my thinking is refined through the process of writing. On this site I share my thoughts on technical topics related to data, AI, and science, as well as on human topics like working effectively within organizations and the experience of being a woman in leadership. Check out my argument for why scientists should vibe code, my keynote on guerilla data science practices, how I think you should use metrics, a new approach to serverless data apps, and what I‚Äôve learned lately about AI for science.\nOutside of work, my family keeps me humble and balanced. My two teenage sons do their best to keep me up to date with modern language and culture. My husband and I are perfecting the art of the weekend camping and mountain biking trip (or camping and snowboarding when we can get it in the Southeast!). My pit bull reminds me that people who sit in front of a computer for too long are boring and it‚Äôs always a good time for a trail run."
  },
  {
    "objectID": "pages/agile-for-ds.html",
    "href": "pages/agile-for-ds.html",
    "title": "Using Agile to Change the Data Science Conversation",
    "section": "",
    "text": "In this post, I described some of the root causes I believe cause common problems for data science teams. So what do we do?\nThe problems facing data science are largely a function of the newness of data science groups to companies and other large organizations. Software development was once in a similar position. One way they addresses these problems was with the Agile approach. I believe we can borrow from this to address the challenges data science faces today.\n\nFor our purposes, I will define Agile as an iterative process focused on delivering maximum value to the end user. The end user for a data scientist is anyone who consumes the result of what we do.\nAs data scientists, we‚Äôre familar with the idea of iteration - we often go through an iterative process during analysis. The essence of Agile is to put the end user more centrally within our iterations.\nThere are three specific Agile practices that can help address the problems data science groups face:\n\nUser Stories\nVertical Slicing\nStakeholder Reviews\n\n\nUser Stories\nUser stories are a way to decribing the work that puts the focus on the value to the end user. It encourages conversations between data scientists and stakeholders that help develop a shared understanding of what the impact will be.\nIt is natural for us as data scientists to describe our work in terms of what we plan to do. User stories give us a framework for shifting to why. The diagram below shows this contrast for an example from the TransLoc data science team. On the left is the initial way we would have described the work as data scientists. On the right is the user story for this work. It follows the traditional form of user stories which is:\nAs a ____, I need to ____, so that I can ____.\n\n\n\nalt text\n\n\nIn my previous post I described one of the problems for data science groups as marginality, or the perception that what we do is tangential to the core work of the organization. The practice of user stories can address this by helping us make sure that we are addressing critical needs, and that people understand that this is the intent of our work.\nAn important point about user stories is that they are not just elaborate wordsmithing. In addition to reframing our communication and conversations with others, they also help reorient our thinking as data scientists. We may have envisioned a technical path to solving a problem, and never questioned our choices. User stories force us to think about the value we are trying to deliver and consider the range of ways we might achieve this. Often there may be simpler approaches that could have the same impact on the end user.\n\n\nVertical Slicing\n\nAnother incredibly valuable Agile concept is vertical slicing, which allows us to get feedback from the end user early and often. It also enables us to ‚Äúmaximize the work not done‚Äù, by apply our resources in small increments, and only continuing to work on projects that continue to deliver value. If you‚Äôve ever done a lot of work to create a great result that no one used, this is the approach for you!\nThe traditional workflow is like a layer cake: we build a project layer by layer, and when it‚Äôs done and frosted, we deliver the results. Vertical slicing focuses on changing this in two ways:\n\nVertical: tackle the work in a way that gets all the way from the bottom layer to the top, so there is actual value to the end user produced\nSlice: narrow the scope to the least amount of work that can deliver some value\n\nThe mantra is find the thinnest vertical slice. The end result of this practice is that we can get feedback with as little work as possible, and determine whether to continue with the next vertical slice or devote resources elsewhere. It can be surprising how much more information we get about what‚Äôs valuable from putting a tangible output in front of users instead of just talking about what we‚Äôre planning to produce. This combats the problem of mystery by providing transparency into what data scientists produce in way that is easy for people to understand, because it‚Äôs oriented around what they get from us as an end user.\n\n\nStakeholder Reviews\nThe final Agile practice that brings together user stories and vertical slicing is stakeholder reviews. This means getting all the stakeholders of the data science group together to review the vertical slices that have been completed, and give input into the prioritization of what to do next. There are three main steps to a stakeholder review:\n\nShow the work that has been completed (and why it was done that way)\nPropose the work to do next in terms of user stories and vertical slices (and why these are the next priorities)\nHave a conversation about 1 and 2, and consider reshuffling priorities accordingly\n\nStakeholder reviews are best done on a regular cadence (at TransLoc we‚Äôre doing these for data science once a month) - this creates momentum and stakeholder engagement as they understand data science impact more and more over time. Stakeholder reviews address the problem of misalignment by exposing all stakeholders to the variety of ways data science work is having and impact, and by encouraging various stakeholders to talk to each other to resolve competing priorities for using data science resources.\n\n\nChanging the Conversation\nThe challenges we face at this early stage of establishing data science groups will not be solved overnight, but I believe these Agile practices are one approach to helping us dissolve these barriers over time. By focusing on the continuous delivery of value to end users, we draw the stakeholders in our organization in, and in the process learn more about how we can maximize our impact."
  },
  {
    "objectID": "pages/serverless-apps.html",
    "href": "pages/serverless-apps.html",
    "title": "Serverless Data Apps",
    "section": "",
    "text": "Serverless Data Apps\nIt‚Äôs not unusual to follow a link from a scientific publication only to arrive at a page for a once useful web application that no longer functions or exists ‚Äì presumably because funding for the project has expired and the person who maintained the app is no longer working on it.\nWith this in mind, and particularly since Focused Research Organizations like EvE Bio are not designed to exist indefinitely, we tried to avoid having the data application we built ever ending up in this situation. Fortunately, a set of relatively new technologies provide a new way to create serverless interactive data apps. What began as a hypothesis that this could work has been proven out over the last year in EvE Bio‚Äôs Data Explorer, which is available to the public.\nThe tech stack for this application is DuckDB, WebAssembly (WASM), Quarto, and Observable JS, all of which are open source and freely available. The end result is a responsive app for data exploration that doesn‚Äôt require a backend server. It exists as a set of files that are uploaded to EvE‚Äôs website, and everything runs locally in the user‚Äôs browser. The app was built by a data scientist and requires no maintenance or monitoring unless new data needs to be added. This reduces the labor cost, and virtually eliminates infrastructure costs. The expertise needed to transition this to a new location is reduced to just copying a folder of files ‚Äì the usual html, css, and images you‚Äôd expect for a website, plus a set of parquet data files.\nThis is the role of each part of the stack:\n\nDuckDB allows for a set of data files in familiar formats to be used as a fast, lightweight analytical database\nWASM makes it possible for DuckDB to work directly in the browser\nQuarto is a technical publishing platform that combines code and text into website form\nObservable JS provides a reactive framework to support user interaction\n\nSince WASM is bundled with DuckDB, and Observable and DuckDB are accessible from Quarto, the developer can work entirely in Quarto.\nWe have been encouraged by the success of this approach and hope it provides inspiration for other apps using this stack!"
  },
  {
    "objectID": "pages/pain-of-ds.html",
    "href": "pages/pain-of-ds.html",
    "title": "The Pain of Data Science in Organizations",
    "section": "",
    "text": "It is the best of data science times, it is the worst of data science times‚Ä¶\nData science is high in the hype cycle and considered the sexiest job of the 21st century. Data scientists are in demand, and the tools to do our jobs are getting better by the month. It‚Äôs a great time to be in data science!\nHowever‚Ä¶ managing a data science group often feels like an uphill battle. The problems are not the data science work itself, they are about doing data science within organizations. At first I thought it was me. But the more data science managers I talked to, the more I heard the same stories over and over again. My conclusion from is that there are three root causes to many of the barriers we face: marginality, mystery, and mis-alignment.\n\n\nMarginality\nMarginality is the perception (or reality) of others that data science is tangential to the core work of the organization.\nA clinical diagnostics company may have a group dedicated to the complex processing required to turn raw instrument results into a meaningful scientific result. Even though they recognize that this is a necessary step in developing diagnostics, the core business of the company is manufacturing and selling diagnostic tests, not analyzing data.\n\n\nMystery\nMystery is the difficulty people throughout the organization have understanding what data science really is.\nIt‚Äôs not uncommon for data science groups to come into existence like this:\n‚ÄúWe have data. We need to get more from our data. Let‚Äôs hire data scientists‚Ä¶‚Äù\n‚ÄúHooray, now we have data science! But what do they actually do? And can I ask without seeming dumb?‚Äù\n\n\nMisalignment\nMisalignment is the poor placement of data science groups within the organizational structure.\nThis can manifest in at least three ways:\n\nData science being entirely in the wrong place ‚Äì such as housed in IT even though all their stakeholders are elsewhere and they don‚Äôt share a mission with IT.\n\n‚ÄúHalf-alignment‚Äù - in which the data science group reports up through a part of the company in which they do some work, but where the most valuable work they deliver is to other departments.\n\nData science groups being pushed down within the organization. Because the groups often start out small, and are sometimes intimidating for non-technical people to manage, they can be placed so far down in the org structure that they don‚Äôt have the eyeline or influence to be effective.\n\n\n\nBarriers to Data Science Impact\nThese three issues can keep data science teams from having the hoped-for impact. They lead to difficulty getting access to data, adding headcount to teams, and being free to focus on the most impactful work.\nAs a maturing field, we need to take on the challenge of making data science work effectively within organizations.\nMy thoughts about ways to do this by borrowing from Agile practices are here."
  },
  {
    "objectID": "pages/asterisks.html",
    "href": "pages/asterisks.html",
    "title": "Jacinda Ardern",
    "section": "",
    "text": "Jacinda Ardern\nI was watching Jon Stewart interview Jacinda Ardern about the documentary ‚ÄúPrime Minister‚Äù when this image suddenly appeared and brought tears to my eyes. It‚Äôs a striking visual representation of something almost unheard of ‚Äì a woman becoming a mother while at the height of power.\n\nThere‚Äôs no question that having a demanding job and taking the lead on parenting and household management the way many moms do represents an uncapped commitment that can feel nearly impossible, even for those of us not running a country. Seeing other women also try to do both simultaneously and well creates a deep sense of camaraderie even with strangers on other continents.\nI once had a graduate intern who casually said ‚ÄúYou don‚Äôt even seem like a mom!‚Äù. It was hard to know how to take this. I think what she meant was that I approached my job as though it were my primary focus. I did take my job seriously. But, I never wanted this to be a tradeoff. I want to be great at my job and be a great mom to my boys, and I hope they‚Äôve felt like I was 100% mom when I was with them.\nI often felt like I should put an asterisk on my professional accomplishments when my kids were young: ‚ú±achieved while also raising two children and running a household. Surely, I thought, it would have been easy for someone with fewer additional responsibilities to do the same things. On the other hand, the day I returned to work after my first parental leave was the day I stopped procrastinating. Knowing your days are unfailingly timeboxed by dropoff and pickup times creates a tremendous sense of focus (desperation?) and can spur creativity and aggressive prioritization.\nAt its best, being all in at work and all in at home is an exhausting but rich, full life. At its worst, it feels like every day is impossible. It‚Äôs an experience that creates a sense of connection with anyone else who is also living it, and the image Jacinda Ardern step into it at such a high level meant a lot."
  },
  {
    "objectID": "pages/onlyness.html",
    "href": "pages/onlyness.html",
    "title": "The Loneliness of Onlyness",
    "section": "",
    "text": "The Loneliness of Onlyness\nMuch has been said about the toxic, sexist work environments that women endure. I have been fortunate to have encountered very little of this; most of the men I‚Äôve worked with have been great people who have treated me as an equal. Even so, there‚Äôs a cost to being an only. Many of the primary teams in my career have been me and a bunch of guys (great guys) ‚Äì and so is my family.\n\nI used to keep track of my record for ‚Äúnumber of men in a meeting without another woman but me‚Äù, and topped out at 25. During that particular meeting one of my male colleagues asked me at lunch ‚Äì ‚Äúhey, did you realize you‚Äôre the only woman here?‚Äù. Yes, sir, I did.\nLater, I joined a software startup as the first data scientist and the first woman in the product and engineering department. I was on the department leadership team with several really wonderful men. It was a great experience. A year later when we our new hired head of product management joined the team for the first time, I was surprised at the sudden sense of relief at no longer being the sole woman. I hadn‚Äôt ever realized the underlying loneliness of being an ‚Äúonly‚Äù, no matter how welcoming the men around me, until it was gone."
  },
  {
    "objectID": "pages/jane-goodall.html",
    "href": "pages/jane-goodall.html",
    "title": "Jane Goodall",
    "section": "",
    "text": "Jane Goodall\nThe privilege I had as a little girl growing up, thinking I could pursue whatever profession I want, is built on the progress of generations of older women. My mother has told me how excited she was when she was finally allowed to get her own credit card without her father or husband signing off (!!). How quickly we take these things for granted.\n\nWhen Jane Goodall died in October 2025, I stopped to read more about her and reflect on what it must have taken to become a prominent woman in science for someone born in the 1930s. I admire her courage and sense of adventure ‚Äì not just to buck the social norms, but also to head into the jungle. I also appreciate that she remained in the public eye, continuing to make things happen, as an elderly woman. Rarely do we see elderly woman as influential in their own right (not via their powerful husbands).\nThe Risky Business podcast had a great episode on how, in addition to being a pioneer as a woman, her insistence on her outsider perspective was critical to her contribution."
  },
  {
    "objectID": "pages/posit-keynote.html",
    "href": "pages/posit-keynote.html",
    "title": "Establishing Data Science",
    "section": "",
    "text": "Establishing Data Science\nPrior to being a CEO, my specialty was establishing data science teams at startups. I was honored to share my learnings about this - and the guerilla data science tactics involved ‚Äì in a keynote talk at the Posit conference in 2023. I wrestle with the gap between the hope for what data science can deliver and the understanding of what it takes to do this successfully, and share some tactics for how to get things off the ground. These are lessons from the trenches in the pre-AI era, but perhaps some of them can inform AI implementation efforts today."
  },
  {
    "objectID": "pages/how-llms-work.html",
    "href": "pages/how-llms-work.html",
    "title": "Data Woman",
    "section": "",
    "text": "What is an AI model under the hood? Basically, just layers of many matrices of numbers that get updated many, many times (matrices - remember linear algebra?). As we wonder at the power of modern AI tools, it‚Äôs great to get a tangible sense of what they are and what training a model really does.\nThis is a great 7 minute video from 3Blue1Brown that explains it with helpful visuals. If you want to go deeper, there is a YouTube series on this channel that has more details on each component."
  },
  {
    "objectID": "pages/metrics-reality.html",
    "href": "pages/metrics-reality.html",
    "title": "The best use of metrics",
    "section": "",
    "text": "The most valuable use of metrics is to 1) create a shared understanding of reality and 2) generate constructive conversation.\nDo this by identifying key metrics, relentlessly revisiting them, and using them as a starting point for discussion.\n\n\n\nFirst, let‚Äôs talk about why creating a shared understanding of reality is an objective worth focusing on. Does everyone in your organization have the same view of how the company is doing, and where the successes and challenges are? Assume no. The default state of affairs is that everyone has a different perspective, each of which is wrong in some way. This inherently leads to out-of-sync decision making, as people make reasonable choices based on different understandings of reality. (For more on this, I recommend this article by Benn Stancil.)\nThere are several reasons why it‚Äôs so hard to have an accurate, shared view of reality.\n\n\n\nEven in the unlikely case that members of an executive team have a common understanding of where things stand, it‚Äôs almost certainly true that individual contributors do not. This is partly due to communication from executives outward. While leaders are immersed in thinking about the big picture and adapting longer term plans, everyone else is focused on the details of the day to day. An executive may have had five meetings about something, and it‚Äôs inherently informing their thinking. They may not even recognize that it hasn‚Äôt been communicated to the rest of the organization ‚Äì or perhaps it has, but without people fully absorbing it. It‚Äôs very common for leaders to think they‚Äôve clearly explained something when the actual level of understanding is little to none.\n\n\n\nWhile company leaders are well informed about some aspects of a company‚Äôs situation, they are often out of touch with the day to day realities. This is natural, as they‚Äôre focused on a different set of activities. However, it often leads to a disconnect on critical issues. This can happen between executives and individual contributors within organizations, and also between entire companies and their customers. Sometimes a single experience can suddenly make this clear. For example, in 2023 Jim Farley, the CEO of Ford, took the EV version of the F-150, the Ford Lightning, on a road trip, where he quickly adjusted his view of reality.\n\n\n\nThere are many ways metrics are used in organizations, particularly to evaluate company and individual performance. In these cases there is an inherent bias towards making things look good. Whether it‚Äôs the CEO pitching the company to investors, the marketing team making a case to customers, executives updating employees, or individuals maximizing metrics tied to their compensation, there are incentives to present the most optimistic version of reality. The problem is that this optimistic version tends to become the main understanding, often without anyone even realizing it.\n\n\n\n\nUsing metrics well is like giving everyone in your organization glasses that suddenly make things clear. To do this, you to carefully select metrics and make them precise, keep returning to them repeatedly over time, and approach them with the goal of understanding and problem solving, rather than using them for positive messaging.\n\n\n\nFirst, decide what elements of your strategy or operations are more critical to represent in metrics. There are probably many; start with just a handful and expand over time. It‚Äôs much better to get this process up and running successfully with three metrics that everyone truly understands, remembers, and can talk about, than to have a comprehensive set that leaves people behind.\nOnce you decide what your first metrics will be, you need to really precisely define them. Try to do this in words, then have someone who works with data try to do it with code (such as SQL, R, or python). Or if you don‚Äôt have such a person, implement a calculation from data to the metric in a spreadsheet. The important thing here is that you start with a standardized set of ‚Äúraw‚Äù data that is updated regularly, and includes the information needed to calculate your metrics. For example, at EvE Bio, we record every assay that enters the assay development process, metadata about the assay type, the date when development started, the protocol number that results, the date the protocol was approved, a checkbox for assays that did not result in a protocol, and a standardized set of reasons for this. From this we can calculate things like protocols published per week, average time in assay development by assay type, assay development success rate, etc. When we look at these metrics, we don‚Äôt ask someone to provide a number, we have it automatically calculated with code directly from the same dataset every time.\nThis might seem overly rigid especially if your metrics aren‚Äôt that hard to calculate. The reason you should still do this with code is that it forces everyone to agree on a single, precise definition of the metric that is consistent over time, and a single version of the data the metric is based on that is also consistent over time. It is very often the case that people verbally agree on a metric to track, but that when someone tries to implement its calculation in code, many specific questions arise. Being forced to work through these up front avoids common problems in which what seem like the same metrics are calculated differently by different people (or even the same person) over time, which immediately makes them less useful. There is no room for hand waving in code.\nNote: It‚Äôs certainly not the case that all important things can be reduced to numbers. However, metrics provide a concrete anchor for our understanding of reality, so it‚Äôs a good place to start. More qualitative information can fill in the picture around the numbers, and tightly coupled quantitative measurement and qualitative research is a powerful combination.\n\n\n\nOnce you have a small set of key metrics that are precisely and automatically calculated, your task is to return to them relentlessly. Continuing to look at the same numbers over time is often the obvious goal, but is easy to stray from. It can seem pedantic, but repetition is necessary to establish things in people‚Äôs thinking. I once worked at a startup where someone was selected at every company meeting to read our mission and our strategy. Sometimes this felt a bit silly, but it was effective. Don‚Äôt worry about overcommunicating, it‚Äôs virtually impossible to do.\nThe most common reason I‚Äôve seen metrics fade from ongoing review is when things aren‚Äôt going as well as expected. Leaders get nervous about calling attention to problems, often because of concerns about damaging morale. However, employees generally pick up on this, and it‚Äôs more empowering to have an opportunity to be part of a solution than to be ‚Äúprotected‚Äù from bad news.\n\n\n\nThe goal of developing a shared understanding of reality is to take effective action. This means facing things head on, both good and bad, rather than trying to change the messaging to reassure everyone about the current situation. If the metrics indicate that reality is not what you hoped, it‚Äôs an opportunity to engage everyone in the problem solving process to get back on track or change course."
  },
  {
    "objectID": "pages/ai-earlyeve.html",
    "href": "pages/ai-earlyeve.html",
    "title": "The State of AI in Drug Development",
    "section": "",
    "text": "Note from the future (2025): this is an article I wrote for the founding team as EvE was just coming into being on the state of AI and its implications for drug development. Consider it a time capsule back to 2023 ‚Äì ages ago in the AI world!"
  },
  {
    "objectID": "pages/ai-earlyeve.html#the-magical-ingredients",
    "href": "pages/ai-earlyeve.html#the-magical-ingredients",
    "title": "The State of AI in Drug Development",
    "section": "The Magical Ingredients",
    "text": "The Magical Ingredients\nThe notable broadly recognized progress of AI-type capabilities in the last few years is the result of three necessary ingredients coming together to produce seemingly magical leaps forward in language, image, and code generation among other things.\nMethods + Compute + Data = MagicüîÆ.\n\nMethods\nNeural networks are the class of methods powering modern advances, but they have been around since the 1940s. Modeled on the human brain, neural networks have layers that begin as a naive structure, but learn from training data what the essential patterns are in an arbitrarily complex way that can function as a black box.\nAfter multiple cycles of favor and disfavor (mostly caused by computational limitations), neural networks emerged in the 2010s in the form of ‚Äúdeep learning‚Äù, which began to consistently demonstrate superior performance on a diverse set of tasks. Deep learning is a term for a neural network with more than three layers.\nThere are many types of neural networks. Some only move in one direction (‚Äúfeed forward‚Äù), some circle back through layers (‚Äúrecurrent‚Äù), some pool local information (‚Äúconvolutional‚Äù), and so forth. Different types are suited to different tasks. The application of neural networks to any particular problem requires a series of judgment calls about how to design and train the system.\nThe application of deep learning in the early 2010s resulted in meaningful advances in image processing tasks, but not in language. The design of language processing approaches was increasingly complex, attempting to represent what humans knew about language in the architecture. Performance was underwhelming.\nThen in the mid-2010s, a team at Google Brain working on language translation discovered the benefits of a different architecture and published the seminal paper Attention Is All You Need (2017). Known as transformers, this approach backed off on the representation of complexity and instead allowed the network more flexibility in learning patterns itself.  A critical feature of this architecture is that it is easily parallelized, leading to the ability to process much larger amounts of data. This essentially represented a tradeoff in which the model was responsible for more of the ‚Äúintelligence‚Äù, but was given much more data from which to learn. This ended up being a very good tradeoff, leading to the impressive language models of the early 2020s.This 2021 blog post from Dale Markowitz is a very accessible high-level introduction to transformers. It describes the key elements of transformers without getting into anything highly technical, and summarizes the broad arc of their impact.\nWhat turns out to be magical about the transformer architecture is that it excels at many tasks well beyond language translation. At the moment it is the golden ticket to progress that has not yet run out, and most of the AI developments since 2021 involve transformers. Expertise is still required to determine how best to apply them to new areas, but for the time being they seem to be broadly applicable across domains. No doubt at some unknown point in the future progress will stall, awaiting another advance in methods.\n\n\nCompute\nThe success of the massive data + massive parallelization approach was only possible due to the availability of massive compute capability, specifically graphical processing units (GPUs). The initial rise of GPUs was for gaming. In the 2010s, they began to be used for deep learning, and then experienced additional demand for crypto mining. The recent AI hype and its demand for GPUs made GPU supplier NVIDIA a trillion dollar company in May 2023.\nWe can assume that compute capability is domain-agnostic. It is expensive, however, so the business model of a given endeavor will determine willingness to pay.\n\n\nData\nThe raw material required to power the AI machine is data. Massive amounts of data. The most prominent AI models were trained on data harvested from publicly available sources ‚Äì writing on the internet, digitized books, digitized art, and code posted to Github. Humanity had already produced the data, and the internet made it machine-ready. Recent learning has demonstrated that the sheer volume of data is critical, with iterative improvements on models largely correlating with the increasing size of training datasets.\nMany of the new models fall into a category dubbed ‚Äúfoundation models‚Äù. Instead of being trained for a specific task, they are allowed to learn from data in a very general way that produces broadly applicable capabilities. These foundation models can then be used as a base from which specific models can be trained using small, specific datasets (a process known as ‚Äúfine-tuning‚Äù). Large language models (LLMs) like GPT are an example of a foundation model. In this sense, datasets are being repurposed across applications to some degree. Regardless, data is by far the most domain-specific of the three ingredients.\nSo, in assessing the AI-readiness and potential in various arenas, we should consider the availability of large scale high quality data first, methods second, and (willingness to pay for) compute third."
  },
  {
    "objectID": "pages/ai-earlyeve.html#fertile-ground-for-ai",
    "href": "pages/ai-earlyeve.html#fertile-ground-for-ai",
    "title": "The State of AI in Drug Development",
    "section": "Fertile Ground for AI?",
    "text": "Fertile Ground for AI?\nDoes the hypothesis that methods, compute, and data are the requirements for AI success hold for biology and drug development? There is some positive evidence.\n\nProtein Folding\nThe most prominent AI triumph in the scientific realm is the AlphaFold protein folding model. The original AlphaFold model from Google DeepMind performed well, but AlphaFold2 (2021) ‚Äì in which the transformer architecture was applied ‚Äì did substantially better. Notably, it out-competed other transformer-based approaches, in a testament to the importance of expertise in applying methods to specific domains and problems. This 2022 Frontier in Bioinformatics article reviews the developments in protein folding models, along with the strengths and weaknesses of the various approaches.\nThe key ingredient of data was available for the protein folding application due to the vast numbers of sequenced proteins, of which a non-trivial portion have solved structures available. AlphaFold was able to take advantage of both this ‚Äúlabeled‚Äù data on structures and learn patterns from the sequences without structures. This represents an important difference between the current AI approaches and more traditional applications of machine learning. Traditionally, this type of prediction model would being limited to the ~150,000 proteins with available structures, which would then need to be split for use in both training and validation processes.  The ability of AI systems to learn effectively from unlabeled data (through ‚Äúunsupervised‚Äù and ‚Äúself-supervised‚Äù processes), provides ways to make use of data without being entirely bottlenecked by expensive or impossible labeling processes.A layperson‚Äôs description of how AlphaFold2 works can be found in this blog post.\nQuickly following after AlphaFold were another type of protein folding models based on large language model approaches. These models rely only on the protein sequence itself (no multi-sequence alignment), and treat amino acids like words and proteins like sentences. ESMFold (from Facebook Research) is an example of this type of model. While less accurate than AlphaFold2, it is much less computationally intensive, and thus can be applied on a metagenomic scale.\nThese models have provided an abundance of structures that are readily available and are in fruitful use by researchers. AlphaFold2 alone has taken the structural coverage for human proteins from 48% to 76%.\n\nA few other key ingredients\nIn addition to the big three ingredients outlined previously, also important for AlphaFold2‚Äôs success were:\n\nThe right cross-disciplinary team in the right working environment\nA problem with strong patterns to learn\n\nIt‚Äôs not clear where critical domain-specific AI developments will happen in the future. The ability to attract, assemble, and support the necessary team has seemed possible only under the wing of major technology companies to date. As AI becomes more mainstream, that may change, but academia and pharma/techbio companies both have some substantial challenges in this regard.\nThanks to evolution and the nature of protein folding itself (with secondary and tertiary structures), the type of patterns AI systems are good at learning are present in the protein folding problem. Not all problems will be as well suited, and consequently may require even larger amounts of data and/or novel or hybrid methods.\n\n\nLimitations and root causes\nProtein folding models are AI success stories, but have weaknesses of particular relevance to drug development. For example, AlphaFold2 has trouble predicting longer loops, which are important because of their surface exposure. It also struggles to predict structures with ligands, DNA/RNA complexes or post-translational modifications. Many of these challenges go back to the nature of the training data itself. Structures sourced from the Protein Data Bank (PDB) can represent many contexts and conditions, and these are not accounted for in the model itself. Other challenges may be due to the complexity of the problem. AlphaFold2 does well at predicting shorter loops, with under 20 residues. Longer, more flexible loops and unstructured regions of proteins generally are inherently harder to predict."
  },
  {
    "objectID": "pages/ai-earlyeve.html#whats-next",
    "href": "pages/ai-earlyeve.html#whats-next",
    "title": "The State of AI in Drug Development",
    "section": "What‚Äôs Next?",
    "text": "What‚Äôs Next?\nProtein folding shows us that AI progress can carry over into biological applications. But does that mean we should expect a near-term rapid acceleration of progress in drug development and therapeutics as a result of AI?\n\nThe Bull Case\nThe bull case for AI is that the biological world is an excellent fit for the nature of AI, and that we‚Äôve just reached the point where data generation at the necessary scale is possible.  DeepMind CEO Demis Hassabis has argued that biology can be seen as a complex information processing system, making it ripe to be decoded by AI systems that can theoretically learn patterns at a scale that humans cannot.This Centry of Biology blog post lays out the big picture (and VC-style optimistic) case for why biology is a great AI target, much better than other applications in the physical world.\nThe nature of data in the biological realm is that it can‚Äôt be scraped from existing sources as training data for LLMs has been from the internet. It requires instruments, measurement systems, and physical substrates. However, there is optimism that now is the time that we are ready to generate the type of data that‚Äôs needed, at least in several key areas.  The ability to sequence, synthesize, and edit DNA at reasonable cost and speed is enabling data generation on a new scale. Whole genome sequencing for millions of people is within reach, potentially creating the type of massive datasets necessary for AI success.One optimistic voice is Daphne Koller, CEO of Insitro and well-respected AI researcher. She believes a few publicly available datasets like the UK Biobank are fit for ML use, but that most data will need to be specifically generated. This McKinsey article has a brief summary of her perspective. A broader, richer conversation is in this Bio Eats World podcast episode. Another such voice is Jakob Uszkoreit, an author of the Google Brain transformers paper, now working on applications of AI to RNA as CEO at Inceptive. He discusses his perspective in this Bio Eats World podcast episode.\nOne path to success could be through the compounding effects of a growing number of specific AI models. As we have models that are very good at a particular task (like AlphaFold is for protein structure prediction), these could then be connected in a modular way to become more than the sum of their parts. This could help us tackle the unfathomable complexity of the biological world one piece at a time, while getting the benefits of chaining capabilities together in a way that can still result in a fully machine-driven system.\nAnother path could be to amass huge amounts of heterogeneous data and impose less structure representing processes as we see them. This tradeoff has served us well recently, and we have generally underestimated the complexity of patterns AI can learn. Perhaps viewing protein folding as a modular capability is not as good as allowing a system to learn from observations that reflect the context in which proteins operate. It‚Äôs possible that large numbers of whole genome sequences paired with digital medical records could power such a system. In the UK, where WGS efforts have been most extensive to date (UK Biobank) and the NHS has extensive medical records in a unified system, the ability to attempt this may be within reach.\nThis Nature article reviews the many steps of the drug discovery process on which GPU computing and deep learning capabilities are having a positive impact.\nAdditionally, advances in lab automation capabilities may unlock the ability to generate and use data on a fundamentally different scale. A virtuous cycle of data collection that feeds back into the models and accelerates their performance could be possible (and some companies are attempting this approach today). These ‚Äúclosed-loop‚Äù systems could operate at a speed and scale inconceivable when human scientists must always be in the loop, leading to an inflection point in progress.\nEven if the progress driven by AI is more incremental than exponential for some time, it has the potential to improve performance at many steps of the drug development process. In an industry with long cycles and high failure rates, AI could lead to substantial business gains even before it becomes truly transformative.\n\n\nThe Bear Case\nThe bear case for AI is that the biological world is orders of magnitude more complex than anything AI has been successfully applied to to date, and our ability to collect data on it is highly imperfect and expensive. The extent of data collection required would be beyond the capacity of any given entity, and the incentives don‚Äôt promise sufficient payoff in a single area to justify even a consortium of players making such a tremendous investment. While more advances akin to those we‚Äôve seen in protein folding are likely for specific cases, and will drive incremental progress, the breadth of progress required to see transformational impact at the level of human health may require many more step change advances in AI capabilities that would likely take decades.\nHints that the current wave of progress could solve some hard problems in biology but leave the many very hard problems untouched come again from protein folding models. Despite the capabilities of AlphaFold, we are unable to model what we might care most about for drug development - binding with compounds.  One can argue that compounds are much less amenable to wrangling by current AI systems because they:In this 2023 article Derek Lowe makes the argument that ligand-binding predictions are a much harder problem than protein folding predictions, and that we lack the necessary data.\n\nhave more complex constructions than sequences of nucleic or amino acids\nhave more possible individual building blocks\nhave no single convenient representation akin to an amino acid sequence\nlack information from what exists in the biological world that constrains the total potential space of possibilities to a more tractable subset\n\nThis 2023 Century of Biology blog post explores the arenas of tangible success and failure-to-date of AI systems in biological applications. The hypothesis put forth is that we‚Äôre showing substantial progress in modality companies, but not in target discovery endeavors, because the ripeness of the problems for AI is fundamentally different.\nWhile the hypothetical number of protein sequences is 20^(sequence length of your choosing), the universe of proteins that exist in the world is much smaller, providing at least an initial fruitful constraint on the problem space. The possible chemical space is comparatively enormous. Furthermore, the specification of the problem for drugs is less clear than for protein folding. Predicting a protein structure from an amino acid sequence is a well specified problem for which there are ‚Äúright‚Äù answers available. Identifying drug candidates is a more complex problem that has to be broken down into components. One step could be identifying compounds that bind to a particular target. This is well specified and can be validated experimentally. However, this is one of many steps necessary to produce an effective drug. The data needed to validate the therapeutic value of drugs is extremely slow and expensive to collect in clinical trials, making the feedback loop quite challenging.\nThis article by Verseon CEO Adityo Prakash (not an unbiased voice) speculates about the difficulties and possibilities of applying AI and computational methods to the chemical space.\nSo, compounds in chemical space may be a very hard problem. Target discovery is also likely to be a hard problem, as it requires modeling more complexity than AI systems have succeeded at to date. Problems like protein folding are certainly challenging, but have the specificity of task and clear measurement of success that AI systems thrive on. Target discovery does not.\nThis 2022 McKinsey article explores the promise and challenges of health data platforms.\nThen there is the very, very hard problem of clinical trials. If progress in identifying potential therapeutics rapidly accelerates, it will still be bottlenecked by the speed and massive expense of clinical trials (which currently make up ~70% of R&D costs). Unless the odds of success in clinical studies increases, it may exceed our ability to move candidates through this critical step.\nAnother challenge is management of medical records data in a way that it can be a useful input for AI learning. Reams of potentially valuable data exist in digital format, but the barriers to making them accessible are substantial.\n\n\nMy Take\nIf I were forced to make predictions‚Ä¶\n\nNext Five Years\n\nProgress in end-to-end drug discovery will be incremental rather than transformational.\n\nSuccess rates in the clinic of ‚ÄúAI drugs‚Äù will be similar to the standard process, but will get to the clinical phase more quickly and with more novel compounds and disease areas than pharma companies have seen. This will fall short of the hype, but will be enough to motivate continued partnerships with and investment in AI-centric companies.\nBut if the current set of drugs in clinical trials has a lower success rate than the existing process, we‚Äôre likely to spend at least five years in the ‚Äútrough of disillusionment‚Äù, with greatly reduced investment. It may then take a major development from a tech company to motivate another round of attempts.\n\nWe‚Äôll see transformational progress outside the area of small molecule drugs, based on genomics and/or biologics. These are the areas that seem most well-suited for major AI impacts using the existing methods and formula.\n\n\n\nTen Years Out\n\n‚ÄúClosed loop‚Äù drug development systems will start to bear fruit, based on the level of scale that automated experimentation has enabled. The impact of these will depend on how much confidence they can generate that their compounds will have high success in the clinic.\nA combination of methodological and computing innovations will make exploration of chemical space more tractable, leading to the ability to design truly novel drugs.\nModels will emerge that take genomics inputs and predict disease states and therapeutic responsiveness, largely ignoring the mechanisms in between. Their progress will be based on the use of AI to process medical records data into an anonymized and usable form across systems, which may require enabling legal/regulatory changes.\n\nIf R&D becomes more efficient with a new set of approaches, what will established pharma companies do?\n\nContinue to partner with techbio companies?\nTry to bring this capability in-house? (which I would expect to have a high rate of failure due to incompatible cultures and ways of operating)\nGet out-competed by new companies who increasingly have the ability to bring the drugs they discover to market on their own?"
  },
  {
    "objectID": "pages/ai-earlyeve.html#how-are-companies-using-ai-today",
    "href": "pages/ai-earlyeve.html#how-are-companies-using-ai-today",
    "title": "The State of AI in Drug Development",
    "section": "How are companies using AI today?",
    "text": "How are companies using AI today?\nA number of companies have been founded in the last decade with the goal of applying ML/AI to drug development. Several of these now have compounds in clinical trials, but it‚Äôs rather early to assess their success. No ‚ÄúAI-designed‚Äù drug has yet achieved FDA approval. This Nature article reflects on the state of this industry and summaries the current clinical status of compounds from this set of companies.\nMost of these companies seem to operate in a general pattern involving:\n\nA ‚Äúfull-stack‚Äù / ‚Äúclosed-loop‚Äù approach in which they develop (or acquire) multiple capabilities with the promise of a virtuous cycle of data generation that accelerates a flywheel of progress\nA proprietary software/data/algorithms platform that integrates their components and adds their AI/ML/compute secret sauce\nPartnerships with pharmaceutical companies\n\nThe nature of the IP portfolios varies more widely with some companies (ex. BenevolentAI) appearing to have a more classic pharma focus on compounds and specific therapeutic areas, and others with ML/AI components and computing/automation methods related to the ‚Äúclosed loop‚Äù capabilities. Generally, these companies seem to acknowledge the importance of generating large amounts of fit-for-ML proprietary datasets, and of being able to integrate several steps of the drug discovery process rather than focusing on mastering a single area. So, a fundamentally different type of effort from DeepMind‚Äôs AlphaFold work."
  },
  {
    "objectID": "pages/schario.html",
    "href": "pages/schario.html",
    "title": "Agile at home",
    "section": "",
    "text": "Agile at home\nDuring the pandemic years when we heard endlessly about the metaverse, I wrote a question on my whiteboard that‚Äôs still there today: Who will do the laundry in the metaverse? I was hearing all these tech guys talk with excitement about how we could live our lives in a virtual world. As a mom who was in the midst of working from home full time while homeschooling my two sons whose public school closed for a year, and also feeding the whole family at home all day every with the associated increase in dirty dishes to handle ‚Ä¶ all I could think in response to the tech bros was ‚Äúis your actual laundry going to get done in the metaverse, or is there someone at home doing it for you in the real, boring world while you‚Äôre optimizing your digital reality‚Äù.\n\nThis is an extreme example of a common phenomenon in which solutions coming out of the tech world seem to come from a typically male experience. We can send people to space, but I still have to physically move laundry from the washer to the dryer at the right time multiple days a week‚Ä¶\nOne thing I appreciate about having mothers in leadership at tech companies is that they sometimes mention things that make it clear that they, too, have to manage their household. And sometimes professional skills help! I use agile practices quite a bit at home (and I know my husband is tired of me talking about iteration with respect to home renovations). Emilie Schario, who I got to know from the dbt analytics engineering community, is one of these people who mentions her mom-related tasks in the context of work ‚Äì like this post using laundry as a lead in to sprint planning."
  },
  {
    "objectID": "pages/bitter-lesson.html",
    "href": "pages/bitter-lesson.html",
    "title": "The State of Being Human",
    "section": "",
    "text": "A unique aspect of AI technology is that it challenges us to think about what it means to be human. This shows up in multiple ways, from AI development to competitions to how we all integrate these tools into our lives and work."
  },
  {
    "objectID": "pages/bitter-lesson.html#letting-ai-learn",
    "href": "pages/bitter-lesson.html#letting-ai-learn",
    "title": "The State of Being Human",
    "section": "Letting AI Learn",
    "text": "Letting AI Learn\nTo get a tangible sense of how this plays out, watch this video from OpenAI showing how cute hide-and-seek playing agents learned new strategies ‚Äì including some that the humans had not anticipated!"
  },
  {
    "objectID": "pages/bitter-lesson.html#the-human-experience",
    "href": "pages/bitter-lesson.html#the-human-experience",
    "title": "The State of Being Human",
    "section": "The Human Experience",
    "text": "The Human Experience\nAnother perspective on the experience of humans grappling with the power of AI comes from this fascinating documentary about the AI AlphaGo playing against the reigning Go champion (as referenced in The Bitter Lesson). It provides a window into the experience of the AI developers as well as the players and spectators watching this test of the unique abilities of the human mind."
  },
  {
    "objectID": "pages/metrics-reality.html#why-we-should-care-about-reality",
    "href": "pages/metrics-reality.html#why-we-should-care-about-reality",
    "title": "How you should use metrics",
    "section": "",
    "text": "First, let‚Äôs talk about why creating a shared understanding of reality is an objective worth focusing on. Does everyone in your organization have the same view of how the company is doing, and where the successes and challenges are? Assume no. Even in the unlikely case that the executive team has a common understanding, it‚Äôs almost certainly true that individual contributors do not. This is partly due to communication from executives outward. It‚Äôs\n\nThere are many other ways metrics are used in organizations, particularly to evaluate company and individual performance. It‚Äôs important to note that in these cases there is an inherent bias towards making things look good. Whether it‚Äôs the CEO pitching the company to investors, the marketing team making a case to customers, executives updating employees, or individuals maximizing metrics tied to their compensation, there are incentives to present the most optimistic version of reality.\narticle by Benn Stancil"
  },
  {
    "objectID": "pages/metrics-reality.html#what-is-reality",
    "href": "pages/metrics-reality.html#what-is-reality",
    "title": "The best use of metrics",
    "section": "",
    "text": "First, let‚Äôs talk about why creating a shared understanding of reality is an objective worth focusing on. Does everyone in your organization have the same view of how the company is doing, and where the successes and challenges are? Assume no. Even in the unlikely case that the executive team has a common understanding, it‚Äôs almost certainly true that individual contributors do not. This is partly due to communication from executives outward. It‚Äôs\n\nThere are many other ways metrics are used in organizations, particularly to evaluate company and individual performance. It‚Äôs important to note that in these cases there is an inherent bias towards making things look good. Whether it‚Äôs the CEO pitching the company to investors, the marketing team making a case to customers, executives updating employees, or individuals maximizing metrics tied to their compensation, there are incentives to present the most optimistic version of reality.\narticle by Benn Stancil"
  },
  {
    "objectID": "pages/metrics-reality.html#what-is-real",
    "href": "pages/metrics-reality.html#what-is-real",
    "title": "The best use of metrics",
    "section": "",
    "text": "First, let‚Äôs talk about why creating a shared understanding of reality is an objective worth focusing on. Does everyone in your organization have the same view of how the company is doing, and where the successes and challenges are? Assume no. The default state of affairs is that everyone has a different perspective, each of which is wrong in some way. This inherently leads to out-of-sync decision making, as people make reasonable choices based on different understandings of reality. (For more on this, I recommend this article by Benn Stancil.)\nThere are several reasons why it‚Äôs so hard to have an accurate, shared view of reality.\n\n\n\nEven in the unlikely case that members of an executive team have a common understanding of where things stand, it‚Äôs almost certainly true that individual contributors do not. This is partly due to communication from executives outward. While leaders are immersed in thinking about the big picture and adapting longer term plans, everyone else is focused on the details of the day to day. An executive may have had five meetings about something, and it‚Äôs inherently informing their thinking. They may not even recognize that it hasn‚Äôt been communicated to the rest of the organization ‚Äì or perhaps it has, but without people fully absorbing it. It‚Äôs very common for leaders to think they‚Äôve clearly explained something when the actual level of understanding is little to none.\n\n\n\nWhile company leaders are well informed about some aspects of a company‚Äôs situation, they are often out of touch with the day to day realities. This is natural, as they‚Äôre focused on a different set of activities. However, it often leads to a disconnect on critical issues. This can happen between executives and individual contributors within organizations, and also between entire companies and their customers. Sometimes a single experience can suddenly make this clear. For example, in 2023 Jim Farley, the CEO of Ford, took the EV version of the F-150, the Ford Lightning, on a road trip, where he quickly adjusted his view of reality.\n\n\n\nThere are many ways metrics are used in organizations, particularly to evaluate company and individual performance. In these cases there is an inherent bias towards making things look good. Whether it‚Äôs the CEO pitching the company to investors, the marketing team making a case to customers, executives updating employees, or individuals maximizing metrics tied to their compensation, there are incentives to present the most optimistic version of reality. The problem is that this optimistic version tends to become the main understanding, often without anyone even realizing it."
  },
  {
    "objectID": "pages/metrics-reality.html#how-to-solve-this",
    "href": "pages/metrics-reality.html#how-to-solve-this",
    "title": "The best use of metrics",
    "section": "",
    "text": "Using metrics well is like giving everyone in your organization glasses that suddenly make things clear. To do this, you to carefully select metrics and make them precise, keep returning to them repeatedly over time, and approach them with the goal of understanding and problem solving, rather than using them for positive messaging.\n\n\n\nFirst, decide what elements of your strategy or operations are more critical to represent in metrics. There are probably many; start with just a handful and expand over time. It‚Äôs much better to get this process up and running successfully with three metrics that everyone truly understands, remembers, and can talk about, than to have a comprehensive set that leaves people behind.\nOnce you decide what your first metrics will be, you need to really precisely define them. Try to do this in words, then have someone who works with data try to do it with code (such as SQL, R, or python). Or if you don‚Äôt have such a person, implement a calculation from data to the metric in a spreadsheet. The important thing here is that you start with a standardized set of ‚Äúraw‚Äù data that is updated regularly, and includes the information needed to calculate your metrics. For example, at EvE Bio, we record every assay that enters the assay development process, metadata about the assay type, the date when development started, the protocol number that results, the date the protocol was approved, a checkbox for assays that did not result in a protocol, and a standardized set of reasons for this. From this we can calculate things like protocols published per week, average time in assay development by assay type, assay development success rate, etc. When we look at these metrics, we don‚Äôt ask someone to provide a number, we have it automatically calculated with code directly from the same dataset every time.\nThis might seem overly rigid especially if your metrics aren‚Äôt that hard to calculate. The reason you should still do this with code is that it forces everyone to agree on a single, precise definition of the metric that is consistent over time, and a single version of the data the metric is based on that is also consistent over time. It is very often the case that people verbally agree on a metric to track, but that when someone tries to implement its calculation in code, many specific questions arise. Being forced to work through these up front avoids common problems in which what seem like the same metrics are calculated differently by different people (or even the same person) over time, which immediately makes them less useful. There is no room for hand waving in code.\nNote: It‚Äôs certainly not the case that all important things can be reduced to numbers. However, metrics provide a concrete anchor for our understanding of reality, so it‚Äôs a good place to start. More qualitative information can fill in the picture around the numbers, and tightly coupled quantitative measurement and qualitative research is a powerful combination.\n\n\n\nOnce you have a small set of key metrics that are precisely and automatically calculated, your task is to return to them relentlessly. Continuing to look at the same numbers over time is often the obvious goal, but is easy to stray from. It can seem pedantic, but repetition is necessary to establish things in people‚Äôs thinking. I once worked at a startup where someone was selected at every company meeting to read our mission and our strategy. Sometimes this felt a bit silly, but it was effective. Don‚Äôt worry about overcommunicating, it‚Äôs virtually impossible to do.\nThe most common reason I‚Äôve seen metrics fade from ongoing review is when things aren‚Äôt going as well as expected. Leaders get nervous about calling attention to problems, often because of concerns about damaging morale. However, employees generally pick up on this, and it‚Äôs more empowering to have an opportunity to be part of a solution than to be ‚Äúprotected‚Äù from bad news.\n\n\n\nThe goal of developing a shared understanding of reality is to take effective action. This means facing things head on, both good and bad, rather than trying to change the messaging to reassure everyone about the current situation. If the metrics indicate that reality is not what you hoped, it‚Äôs an opportunity to engage everyone in the problem solving process to get back on track or change course."
  },
  {
    "objectID": "pages/vibe-coding.html",
    "href": "pages/vibe-coding.html",
    "title": "Why scientists should vibe code",
    "section": "",
    "text": "What I mean by ‚Äúvibe coding‚Äù here is telling an AI tool what you want to create with code, and letting it write most or all of the code for you. It has advantages and pitfalls. My argument here is that it can be a valuable activity for scientists to try, especially for data visualization.\nMost scientists have software they use to graph data. While this can be a useful tool, I frequently see scientists present and explore their data in sub-optimal ways because they‚Äôre constrained by what they can easily do with their software. People who can make graphs with code have a lot more flexibility, and with experience can generate many possible visualizations of the same data to find the best approach. This is typically an iterative process, and works best when programmtic graphing skills and deep understanding of the data at hand are both represented. In the past this has often meant that two people need to collaborate, which is more cumbersome and hence less likely to happen. Modern AI tools, however, can put this capability in the hands of the scientist who collected the data.\nI did a lunch-and-learn session about how to do this for a group of scientists that I work with at EvE Bio. One of them took it to heart, downloaded R and RStudio and, in a few hours on his own with Claude, generated a complex visualization of our dataset that he had always wanted to have. He was then able to re-run this code on future versions of this dataset.\n\n\nWhat I‚Äôm proposing is this:\n\nA scientist describes their well-organized dataset and a graph they want to make to an AI tool like Claude or ChatGPT (I‚Äôll assume Claude here)\nClaude generates code to make the graph\nThe scientist runs the code on their local computer and inspects the output\nThere is a series of back-and-forth followups to try different things, until a satisfying end result is reached\nThe scientist double-checks key results for accuracy\n\nWhat we‚Äôre not doing here is giving Claude the dataset, asking it to do an analysis for us, or letting Claude modify code directly on our computer (all of these things are possible, but not necessary).\n\n\n\nIt‚Äôs helpful to see how this works in detail. I‚Äôm going to use the babynames dataset, which comes from the social security administration and is easily accessible in R from the babynames package. (For data generated in the lab, there would typically be a file (csv, etc.) of data that you would want to read in with code, and you can ask Claude how to do that (something like this: data &lt;- read_csv('data/my_data.csv')).)\nI started with this prompt to Claude:\n\nI am using R and the tidyverse package, but I don‚Äôt have experience coding with R. I want to use the dataset from the babynames package. It is called babynames and has columns year, sex, name, n, and prop. Values of the sex column are M or F. I want to make a plot of the babies with each name over time. Let‚Äôs start with the name Mary for females. How do I use R to plot this over time?\n\nClaude responded with this code, and an explanation of what it does. The explanation is helpful both for learning and to check that what Claude is doing is what you want.\n\nThe next step is to copy this chunk of code into a file (like babynames.R) in RStudio (the easiest place to run R code). Run this code, and you get a plot like this:\n\nSince that looks good, I took the next step with this prompt:\n\nI like that plot. I‚Äôd like the y axis labels to have commas in the numbers. And now I‚Äôd like to select the 10 most common female names in the year 1900 and plot each of them so I can see how they compare.\n\nWhen I copy and run the updated code, I get a plot like this:\n\nAnd then with another prompt:\n\nLet‚Äôs extend that to 25 names and plot them each in their own subgraph.\n\nResulting in this:\n\nThis process of back and forth can go on as long as necessary as you explore and develop the end result.\n\n\n\nThere are two main challenges to get this working: 1) Getting the setup and basic mechanics of running code in place and 2) Getting your data in a good format to use with code.\nIf you have a programmer you can ask about getting started, that makes things easier. If not, this is another place where asking Claude can be helpful.\nFor data organization, there are two things to tackle. First you need to understand what type of format to aim for, and then you need to know how to get your data into that format easily. If you have a small dataset, this may be easy to do by hand, but for other cases, you can also have Claude help generate code to rearrange and combine your data (but this requires checking the results carefully). The organization that works well for programming with data follows ‚Äútidy data‚Äù principles. In short, each column should be a variable, each row should be an observation, and each cell should have one value. If you‚Äôre using a spreadsheet, things will be much easier if your data starts in cell A1 and there is a single row at the top with a name for each column.\n\n\n\n\nUse AI for things where you can check the results quickly and reliably (like data visualization)\nDo one step at a time, iteratively\nProvide context and describe what you want\nAsk Claude how you can check things\nRead the explanations of what it‚Äôs doing\nIf you get an error when running code, send it to Claude for troubleshooting\nBe persistent; doing this well takes some practice"
  },
  {
    "objectID": "pages/vibe-coding.html#what-this-means-in-practice",
    "href": "pages/vibe-coding.html#what-this-means-in-practice",
    "title": "Why scientists should vibe code",
    "section": "",
    "text": "What I‚Äôm proposing is this:\n\nA scientist describes their well-organized dataset and a graph they want to make to an AI tool like Claude or ChatGPT (I‚Äôll assume Claude here)\nClaude generates code to make the graph\nThe scientist runs the code on their local computer and inspects the output\nThere is a series of back-and-forth followups to try different things, until a satisfying end result is reached\nThe scientist double-checks key results for accuracy\n\nWhat we‚Äôre not doing here is giving Claude the dataset, asking it to do an analysis for us, or letting Claude modify code directly on our computer (all of these things are possible, but not necessary)."
  },
  {
    "objectID": "pages/vibe-coding.html#an-example",
    "href": "pages/vibe-coding.html#an-example",
    "title": "Why scientists should vibe code",
    "section": "",
    "text": "It‚Äôs helpful to see how this works in detail. I‚Äôm going to use the babynames dataset, which comes from the social security administration and is easily accessible in R from the babynames package. (For data generated in the lab, there would typically be a file (csv, etc.) of data that you would want to read in with code, and you can ask Claude how to do that (something like this: data &lt;- read_csv('data/my_data.csv')).)\nI started with this prompt to Claude:\n\nI am using R and the tidyverse package, but I don‚Äôt have experience coding with R. I want to use the dataset from the babynames package. It is called babynames and has columns year, sex, name, n, and prop. Values of the sex column are M or F. I want to make a plot of the babies with each name over time. Let‚Äôs start with the name Mary for females. How do I use R to plot this over time?\n\nClaude responded with this code, and an explanation of what it does. The explanation is helpful both for learning and to check that what Claude is doing is what you want.\n\nThe next step is to copy this chunk of code into a file (like babynames.R) in RStudio (the easiest place to run R code). Run this code, and you get a plot like this:\n\nSince that looks good, I took the next step with this prompt:\n\nI like that plot. I‚Äôd like the y axis labels to have commas in the numbers. And now I‚Äôd like to select the 10 most common female names in the year 1900 and plot each of them so I can see how they compare.\n\nWhen I copy and run the updated code, I get a plot like this:\n\nAnd then with another prompt:\n\nLet‚Äôs extend that to 25 names and plot them each in their own subgraph.\n\nResulting in this:\n\nThis process of back and forth can go on as long as necessary as you explore and develop the end result."
  },
  {
    "objectID": "pages/vibe-coding.html#preparing-data",
    "href": "pages/vibe-coding.html#preparing-data",
    "title": "Why scientists should vibe code",
    "section": "",
    "text": "For data generated in the lab, there would typically be a file (csv, etc.) of data that you would want to read in with code, and you can ask Claude how to do that (something like this: data &lt;- read_csv('data/my_data.csv'))."
  },
  {
    "objectID": "pages/vibe-coding.html#challenges",
    "href": "pages/vibe-coding.html#challenges",
    "title": "Why scientists should vibe code",
    "section": "",
    "text": "There are two main challenges to get this working: 1) Getting the setup and basic mechanics of running code in place and 2) Getting your data in a good format to use with code.\nIf you have a programmer you can ask about getting started, that makes things easier. If not, this is another place where asking Claude can be helpful.\nFor data organization, there are two things to tackle. First you need to understand what type of format to aim for, and then you need to know how to get your data into that format easily. If you have a small dataset, this may be easy to do by hand, but for other cases, you can also have Claude help generate code to rearrange and combine your data (but this requires checking the results carefully). The organization that works well for programming with data follows ‚Äútidy data‚Äù principles. In short, each column should be a variable, each row should be an observation, and each cell should have one value. If you‚Äôre using a spreadsheet, things will be much easier if your data starts in cell A1 and there is a single row at the top with a name for each column."
  },
  {
    "objectID": "pages/vibe-coding.html#keys-to-success",
    "href": "pages/vibe-coding.html#keys-to-success",
    "title": "Why scientists should vibe code",
    "section": "",
    "text": "Use AI for things where you can check the results quickly and reliably (like data visualization)\nDo one step at a time, iteratively\nProvide context and describe what you want\nAsk Claude how you can check things\nRead the explanations of what it‚Äôs doing\nIf you get an error when running code, send it to Claude for troubleshooting\nBe persistent; doing this well takes some practice"
  },
  {
    "objectID": "pages/ether0.html",
    "href": "pages/ether0.html",
    "title": "Data Woman",
    "section": "",
    "text": "One of EvE‚Äôs founding hypotheses was that comprehensive pharmome data could serve as the experimental foundation for developing AI models for science. I was thrilled to see this put into practice by FutureHouse, where they leveraged EvE‚Äôs dataset as part of the training and validation of ether0, their chemistry-focused model. This work revealed an important insight: modern domain-specific AI models can be trained with remarkable data efficiency. By building on existing capabilities like AI reasoning and optimizing the approach for the task at hand, exceptional science models can be developed with data that‚Äôs within our reach.\n\nSomething that became clearer to me about modern AI (by modern I mean - in 2025!) is a way in which it‚Äôs now fundamentally different from classic machine learning (even though the underlying mathematical mechanism is not as different as people might think). Machine learning models are typically developed in isolation - based on one dataset, albeit perhaps a very large one brought together from many sources. The model is built based on what can be learned from this data, starting from scratch. Modern AI models, however, can build on the models that came before them, borrowing and adapting capabilities to the task at hand.\n\nThis is how the ether0 model was created. They started with an open base model (Mistral-24B-Instruct) ‚Äì the kind that‚Äôs capable of carrying on a chat conversation. Then they used another open reasoning model (DeepSeek-R1) to generate reasoning ‚Äútraces‚Äù about the type of chemistry tasks ether0 was designed for. An interesting note is that R1 (the reasoning model) had accuracy below 1% at actually carrying out these tasks. Despite this, using this output to train the base model how to reason about chemistry led to improved performance in the end. It‚Äôs only at this point, after a base AI model was trained on the output of another AI model, that data came to bear on further developing into the model. The foundation represents a tremendous set of capabilities ‚Äì language, reasoning, and broad chemistry knowledge ‚Äì on which to build.\nBut first, what is a reasoning trace, you say? This is an example below. The reasoning model is given a chemistry task, it ‚Äúthinks out loud‚Äù in a particular way to reason through the problem, then provides an answer (presumably an incorrect one in this case). It‚Äôs the thinking that‚Äôs used to train the base model to reason, by providing it with a large number of these types of outputs.\n\nAfter this process, the next step was using reinforcement learning to train the model to optimize its performance on the various chemistry tasks at hand. Reinforcement learning is a process by which the AI developers design a reward function that scores the answer the model provides when given a task to accomplish. The reward function in this case requires both the right format and an accurate answer. The accuracy of the answer is evaluated based on ‚Äúground truth‚Äù data. This is where EvE comes in. Our pharmome dataset was used to give the model feedback on its performance on the receptor binding task. Given this reward function, the model is let loose to figure out how to do the task best, improving little by little over many iterations. This process, and our understanding that this is the best structure for AI training, is fascinating in itself. I‚Äôve written more about it here.\nIn the end, the developers discovered that adding reasoning capabilities before carrying out reinforcement learning and distilling it all into a single model, leads to exceptional performance on some tasks but not others. They were able to tie this back to the benefit of reasoning for particular types of tasks. This indicates an important direction for future work, in which different types of models can be deployed for different tasks, optimizing the overall results."
  }
]